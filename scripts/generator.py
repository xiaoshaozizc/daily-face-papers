#!/usr/bin/env python3
"""
README ç”Ÿæˆè„šæœ¬
æ ¹æ®è·å–çš„è®ºæ–‡æ•°æ®ç”Ÿæˆ Markdown æ ¼å¼çš„æ¯æ—¥æ¨è
"""

import os
import json
from datetime import datetime
from typing import Dict, List


class ReadmeGenerator:
    """README ç”Ÿæˆå™¨"""

    def __init__(self, repo_name: str = "daily-face-papers"):
        self.repo_name = repo_name
        self.today = datetime.now().strftime("%Y-%m-%d")

    def generate_readme(self, papers: Dict[str, List[Dict]]) -> str:
        """
        ç”Ÿæˆ README å†…å®¹

        Args:
            papers: è®ºæ–‡æ•°æ®å­—å…¸

        Returns:
            Markdown æ ¼å¼çš„ README å†…å®¹
        """
        all_papers = papers.get("all", [])

        # ç”Ÿæˆå¤´éƒ¨
        content = self._generate_header()

        # ç»Ÿè®¡ä¿¡æ¯
        content += self._generate_stats(papers)

        # è®ºæ–‡åˆ—è¡¨
        content += self._generate_paper_list(all_papers)

        # å½’æ¡£é“¾æ¥
        content += self._generate_archive_section()

        # æ›´æ–°æ—¥å¿—
        content += self._generate_changelog()

        return content

    def _generate_header(self) -> str:
        """ç”Ÿæˆå¤´éƒ¨ä¿¡æ¯"""
        return f"""# æ¯æ—¥äººè„¸è¯†åˆ«/ç”Ÿæˆè®ºæ–‡æ¨è

![Last Updated](https://img.shields.io/badge/last_updated-{self.today}-blue)
![Paper Count](https://img.shields.io/badge/papers_today-6+-green)

æœ¬é¡¹ç›®æ¯æ—¥è‡ªåŠ¨ä» [arXiv](https://arxiv.org) æŠ“å–äººè„¸è¯†åˆ«å’Œäººè„¸ç”Ÿæˆé¢†åŸŸçš„æœ€æ–°è®ºæ–‡ã€‚

## ğŸ“Œ ä»Šæ—¥æ¨è ({self.today})

---

"""

    def _generate_stats(self, papers: Dict[str, List[Dict]]) -> str:
        """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
        rec_count = len(papers.get("face_recognition", []))
        gen_count = len(papers.get("face_generation", []))
        sources = papers.get("sources", {})

        # ç”Ÿæˆæ¥æºç»Ÿè®¡
        source_lines = []
        for source, count in sources.items():
            if count > 0:
                source_lines.append(f"- **{source}**: {count} ç¯‡")

        source_str = "\n".join(source_lines) if source_lines else "- arXiv: 0 ç¯‡"

        return f"""### ğŸ“Š ä»Šæ—¥ç»Ÿè®¡

**è®ºæ–‡åˆ†ç±»:**
- **äººè„¸è¯†åˆ«è®ºæ–‡**: {rec_count} ç¯‡
- **äººè„¸ç”Ÿæˆè®ºæ–‡**: {gen_count} ç¯‡
- **æ€»è®¡**: {rec_count + gen_count} ç¯‡

**æ¥æºç»Ÿè®¡:**
{source_str}

> ğŸ“¡ æ•°æ®æ¥æº: arXiv, CVPR, ICCV, ECCV, NeurIPS ç­‰ä¼šè®®/é¢„å°æœ¬

---

"""

    def _generate_paper_list(self, papers: List[Dict]) -> str:
        """ç”Ÿæˆè®ºæ–‡åˆ—è¡¨"""
        if not papers:
            return "ä»Šæ—¥æš‚æ— æ–°è®ºæ–‡ã€‚\n"

        content = "### ğŸ“„ è®ºæ–‡åˆ—è¡¨\n\n"

        for i, paper in enumerate(papers, 1):
            content += self._format_paper(i, paper)

        return content

    def _format_paper(self, index: int, paper: Dict) -> str:
        """æ ¼å¼åŒ–å•ä¸ªè®ºæ–‡"""
        # åˆ†ç±»æ ‡ç­¾
        category_emoji = "ğŸ”" if paper.get("category") == "äººè„¸è¯†åˆ«" else "ğŸ¨"
        category_color = "è¯†åˆ«" if paper.get("category") == "äººè„¸è¯†åˆ«" else "ç”Ÿæˆ"

        # æ ¼å¼åŒ–ä½œè€…
        authors = ", ".join(paper["authors"]) if paper["authors"] else "Unknown"

        return f"""{index}. **{paper['title']}**

   - ğŸ·ï¸ åˆ†ç±»: {category_emoji} {paper.get('category', 'äººè„¸ç”Ÿæˆ')}
   - ğŸ‘¤ ä½œè€…: {authors}
   - ğŸ“… å‘å¸ƒæ—¥æœŸ: {paper['published']}
   - ğŸ“– ç®€ä»‹: {paper['summary']}

   **é“¾æ¥**: [arXiv]({paper['arxiv_link']}) | [PDF]({paper['pdf_link']})

---

"""

    def _generate_archive_section(self) -> str:
        """ç”Ÿæˆå½’æ¡£éƒ¨åˆ†"""
        year = datetime.now().year

        return f"""## ğŸ“ å†å²å½’æ¡£

- [{year} å¹´è®ºæ–‡å½’æ¡£](./papers/{year}.md)

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue æ¨èä¼˜è´¨è®ºæ–‡ï¼

## ğŸ“„ License

MIT License

---

*æœ¬é¡¹ç›®ç”± GitHub Actions è‡ªåŠ¨æ›´æ–°*
"""

    def _generate_changelog(self) -> str:
        """ç”Ÿæˆæ›´æ–°æ—¥å¿—"""
        return f"""

---
## ğŸ“ æ›´æ–°æ—¥å¿—

### {self.today}
- æ¯æ—¥è®ºæ–‡æ¨èæ›´æ–°
- å…±æ”¶å½• {self.today} å‘å¸ƒçš„è®ºæ–‡
"""

    def generate_archive(self, papers: List[Dict], year: int) -> str:
        """ç”Ÿæˆå½’æ¡£æ–‡ä»¶"""
        content = f"""# {year} å¹´äººè„¸è¯†åˆ«/ç”Ÿæˆè®ºæ–‡æ±‡æ€»

æœ¬æ–‡ä»¶æ”¶å½•äº† {year} å¹´å‘å¸ƒçš„æ‰€æœ‰äººè„¸ç›¸å…³è®ºæ–‡ã€‚

## ç›®å½•

"""

        # æŒ‰æœˆä»½åˆ†ç»„
        by_month = {}
        for paper in papers:
            month = paper["published"][:7]  # YYYY-MM
            if month not in by_month:
                by_month[month] = []
            by_month[month].append(paper)

        # ç”Ÿæˆæœˆä»½é“¾æ¥
        for month in sorted(by_month.keys(), reverse=True):
            content += f"- [{month}](./{month}.md)\n"

        # æ·»åŠ æ¯æœˆè¯¦æƒ…
        for month in sorted(by_month.keys(), reverse=True):
            content += f"\n## {month}\n\n"
            for i, paper in enumerate(by_month[month], 1):
                content += f"{i}. [{paper['title']}]({paper['arxiv_link']}) - {paper['published']}\n"

        return content

    def save_readme(self, content: str, output_path: str = "README.md"):
        """ä¿å­˜ README æ–‡ä»¶"""
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(content)
        print(f"README å·²ä¿å­˜åˆ°: {output_path}")

    def save_papers_json(self, papers: Dict[str, List[Dict]], output_path: str = "papers.json"):
        """ä¿å­˜è®ºæ–‡æ•°æ®ä¸º JSON"""
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(papers, f, ensure_ascii=False, indent=2)
        print(f"è®ºæ–‡æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")


def main():
    """æµ‹è¯•ç”Ÿæˆå™¨"""
    # æ¨¡æ‹Ÿæ•°æ®
    sample_papers = {
        "face_recognition": [
            {
                "id": "2401.12345",
                "title": "Sample Face Recognition Paper",
                "authors": ["Author One", "Author Two"],
                "summary": "This is a sample paper about face recognition...",
                "arxiv_link": "https://arxiv.org/abs/2401.12345",
                "pdf_link": "https://arxiv.org/pdf/2401.12345.pdf",
                "published": "2024-01-15",
                "category": "äººè„¸è¯†åˆ«",
            }
        ],
        "face_generation": [
            {
                "id": "2401.67890",
                "title": "Sample Face Generation Paper",
                "authors": ["Author Three", "Author Four"],
                "summary": "This is a sample paper about face generation...",
                "arxiv_link": "https://arxiv.org/abs/2401.67890",
                "pdf_link": "https://arxiv.org/pdf/2401.67890.pdf",
                "published": "2024-01-14",
                "category": "äººè„¸ç”Ÿæˆ",
            }
        ],
        "all": [
            {
                "id": "2401.12345",
                "title": "Sample Face Recognition Paper",
                "authors": ["Author One", "Author Two"],
                "summary": "This is a sample paper about face recognition...",
                "arxiv_link": "https://arxiv.org/abs/2401.12345",
                "pdf_link": "https://arxiv.org/pdf/2401.12345.pdf",
                "published": "2024-01-15",
                "category": "äººè„¸è¯†åˆ«",
            },
            {
                "id": "2401.67890",
                "title": "Sample Face Generation Paper",
                "authors": ["Author Three", "Author Four"],
                "summary": "This is a sample paper about face generation...",
                "arxiv_link": "https://arxiv.org/abs/2401.67890",
                "pdf_link": "https://arxiv.org/pdf/2401.67890.pdf",
                "published": "2024-01-14",
                "category": "äººè„¸ç”Ÿæˆ",
            }
        ]
    }

    generator = ReadmeGenerator()
    readme_content = generator.generate_readme(sample_papers)

    print(readme_content)


if __name__ == "__main__":
    main()
